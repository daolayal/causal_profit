{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "def make_uplift_classification(n_samples=1000,\n",
    "                               treatment_name=['control', 'treatment1', 'treatment2', 'treatment3'],\n",
    "                               y_name='conversion',\n",
    "                               n_classification_features=10,\n",
    "                               n_classification_informative=5,\n",
    "                               n_classification_redundant=0,\n",
    "                               n_classification_repeated=0,\n",
    "                               n_uplift_increase_dict={'treatment1': 2, 'treatment2': 2, 'treatment3': 2},\n",
    "                               n_uplift_decrease_dict={'treatment1': 0, 'treatment2': 0, 'treatment3': 0},\n",
    "                               delta_uplift_increase_dict={'treatment1': 0.02, 'treatment2': 0.05, 'treatment3': 0.1},\n",
    "                               delta_uplift_decrease_dict={'treatment1': 0., 'treatment2': 0., 'treatment3': 0.},\n",
    "                               n_uplift_increase_mix_informative_dict={'treatment1': 1, 'treatment2': 1, 'treatment3': 1},\n",
    "                               n_uplift_decrease_mix_informative_dict={'treatment1': 0, 'treatment2': 0, 'treatment3': 0},\n",
    "                               positive_class_proportion=0.5,\n",
    "                               random_seed=20190101):\n",
    "    \"\"\"Generate a synthetic dataset for classification uplift modeling problem.\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_samples : int, optional (default=1000)\n",
    "        The number of samples to be generated for each treatment group.\n",
    "    treatment_name: list, optional (default = ['control','treatment1','treatment2','treatment3'])\n",
    "        The list of treatment names.\n",
    "    y_name: string, optional (default = 'conversion')\n",
    "        The name of the outcome variable to be used as a column in the output dataframe.\n",
    "    n_classification_features: int, optional (default = 10)\n",
    "        Total number of features for base classification\n",
    "    n_classification_informative: int, optional (default = 5)\n",
    "        Total number of informative features for base classification\n",
    "    n_classification_redundant: int, optional (default = 0)\n",
    "        Total number of redundant features for base classification\n",
    "    n_classification_repeated: int, optional (default = 0)\n",
    "        Total number of repeated features for base classification\n",
    "    n_uplift_increase_dict: dictionary, optional (default: {'treatment1': 2, 'treatment2': 2, 'treatment3': 2})\n",
    "        Number of features for generating positive treatment effects for corresponding treatment group.\n",
    "        Dictionary of {treatment_key: number_of_features_for_increase_uplift}.\n",
    "    n_uplift_decrease_dict: dictionary, optional (default: {'treatment1': 0, 'treatment2': 0, 'treatment3': 0})\n",
    "        Number of features for generating negative treatment effects for corresponding treatment group.\n",
    "        Dictionary of {treatment_key: number_of_features_for_increase_uplift}.\n",
    "    delta_uplift_increase_dict: dictionary, optional (default: {'treatment1': .02, 'treatment2': .05, 'treatment3': .1})\n",
    "        Positive treatment effect created by the positive uplift features on the base classification label.\n",
    "        Dictionary of {treatment_key: increase_delta}.\n",
    "    delta_uplift_decrease_dict: dictionary, optional (default: {'treatment1': 0., 'treatment2': 0., 'treatment3': 0.})\n",
    "        Negative treatment effect created by the negative uplift features on the base classification label.\n",
    "        Dictionary of {treatment_key: increase_delta}.\n",
    "    n_uplift_increase_mix_informative_dict: dictionary, optional (default: {'treatment1': 1, 'treatment2': 1, 'treatment3': 1})\n",
    "        Number of positive mix features for each treatment. The positive mix feature is defined as a linear combination\n",
    "        of a randomly selected informative classification feature and a randomly selected positive uplift feature.\n",
    "        The linear combination is made by two coefficients sampled from a uniform distribution between -1 and 1.\n",
    "    n_uplift_decrease_mix_informative_dict: dictionary, optional (default: {'treatment1': 0, 'treatment2': 0, 'treatment3': 0})\n",
    "        Number of negative mix features for each treatment. The negative mix feature is defined as a linear combination\n",
    "        of a randomly selected informative classification feature and a randomly selected negative uplift feature. The\n",
    "        linear combination is made by two coefficients sampled from a uniform distribution between -1 and 1.\n",
    "    positive_class_proportion: float, optional (default = 0.5)\n",
    "        The proportion of positive label (1) in the control group.\n",
    "    random_seed : int, optional (default = 20190101)\n",
    "        The random seed to be used in the data generation process.\n",
    "    Returns\n",
    "    -------\n",
    "    df_res : DataFrame\n",
    "        A data frame containing the treatment label, features, and outcome variable.\n",
    "    x_name : list\n",
    "        The list of feature names generated.\n",
    "    Notes\n",
    "    -----\n",
    "    The algorithm for generating the base classification dataset is adapted from the make_classification method in the\n",
    "    sklearn package, that uses the algorithm in Guyon [1] designed to generate the \"Madelon\" dataset.\n",
    "    References\n",
    "    ----------\n",
    "    .. [1] I. Guyon, \"Design of experiments for the NIPS 2003 variable\n",
    "            selection benchmark\", 2003.\n",
    "    \"\"\"\n",
    "    # set seed\n",
    "    np.random.seed(seed=random_seed)\n",
    "\n",
    "    # create data frame\n",
    "    df_res = pd.DataFrame()\n",
    "\n",
    "    # generate treatment key\n",
    "    n_all = n_samples * len(treatment_name)\n",
    "    treatment_list = []\n",
    "    for ti in treatment_name:\n",
    "        treatment_list += [ti] * n_samples\n",
    "    treatment_list = np.random.permutation(treatment_list)\n",
    "    df_res['treatment_group_key'] = treatment_list\n",
    "\n",
    "    # generate features and labels\n",
    "    X1, Y1 = make_classification(n_samples=n_all, n_features=n_classification_features,\n",
    "                                 n_informative=n_classification_informative, n_redundant=n_classification_redundant,\n",
    "                                 n_repeated=n_classification_repeated, n_clusters_per_class=1,\n",
    "                                 weights=[1-positive_class_proportion, positive_class_proportion])\n",
    "\n",
    "    x_name = []\n",
    "    x_informative_name = []\n",
    "    for xi in range(n_classification_informative):\n",
    "        x_name_i = 'x' + str(len(x_name)+1) + '_informative'\n",
    "        x_name.append(x_name_i)\n",
    "        x_informative_name.append(x_name_i)\n",
    "        df_res[x_name_i] = X1[:, xi]\n",
    "    for xi in range(n_classification_redundant):\n",
    "        x_name_i = 'x' + str(len(x_name)+1) + '_redundant'\n",
    "        x_name.append(x_name_i)\n",
    "        df_res[x_name_i] = X1[:, n_classification_informative+xi]\n",
    "    for xi in range(n_classification_repeated):\n",
    "        x_name_i = 'x' + str(len(x_name)+1) + '_repeated'\n",
    "        x_name.append(x_name_i)\n",
    "        df_res[x_name_i] = X1[:, n_classification_informative+n_classification_redundant+xi]\n",
    "\n",
    "    for xi in range(n_classification_features - n_classification_informative - n_classification_redundant\n",
    "                    - n_classification_repeated):\n",
    "        x_name_i = 'x' + str(len(x_name)+1) + '_irrelevant'\n",
    "        x_name.append(x_name_i)\n",
    "        df_res[x_name_i] = np.random.normal(0, 1, n_all)\n",
    "\n",
    "    # default treatment effects\n",
    "    Y = Y1.copy()\n",
    "    Y_increase = np.zeros_like(Y1)\n",
    "    Y_decrease = np.zeros_like(Y1)\n",
    "\n",
    "    # generate uplift (positive)\n",
    "    for treatment_key_i in treatment_name:\n",
    "        treatment_index = df_res.index[df_res['treatment_group_key'] == treatment_key_i].tolist()\n",
    "        if treatment_key_i in n_uplift_increase_dict and n_uplift_increase_dict[treatment_key_i] > 0:\n",
    "            x_uplift_increase_name = []\n",
    "            adjust_class_proportion = (delta_uplift_increase_dict[treatment_key_i]) / (1-positive_class_proportion)\n",
    "            X_increase, Y_increase = make_classification(n_samples=n_all,\n",
    "                                                         n_features=n_uplift_increase_dict[treatment_key_i],\n",
    "                                                         n_informative=n_uplift_increase_dict[treatment_key_i],\n",
    "                                                         n_redundant=0,\n",
    "                                                         n_clusters_per_class=1,\n",
    "                                                         weights=[1-adjust_class_proportion, adjust_class_proportion])\n",
    "            for xi in range(n_uplift_increase_dict[treatment_key_i]):\n",
    "                x_name_i = 'x' + str(len(x_name)+1) + '_uplift_increase'\n",
    "                x_name.append(x_name_i)\n",
    "                x_uplift_increase_name.append(x_name_i)\n",
    "                df_res[x_name_i] = X_increase[:, xi]\n",
    "            Y[treatment_index] = Y[treatment_index] + Y_increase[treatment_index]\n",
    "            if n_uplift_increase_mix_informative_dict[treatment_key_i] > 0:\n",
    "                for xi in range(n_uplift_increase_mix_informative_dict[treatment_key_i]):\n",
    "                    x_name_i = 'x' + str(len(x_name)+1) + '_increase_mix'\n",
    "                    x_name.append(x_name_i)\n",
    "                    df_res[x_name_i] = (np.random.uniform(-1, 1) * df_res[np.random.choice(x_informative_name)]\n",
    "                                        + np.random.uniform(-1, 1) * df_res[np.random.choice(x_uplift_increase_name)])\n",
    "\n",
    "    # generate uplift (negative)\n",
    "    for treatment_key_i in treatment_name:\n",
    "        treatment_index = df_res.index[df_res['treatment_group_key'] == treatment_key_i].tolist()\n",
    "        if treatment_key_i in n_uplift_decrease_dict and n_uplift_decrease_dict[treatment_key_i] > 0:\n",
    "            x_uplift_decrease_name = []\n",
    "            adjust_class_proportion = (delta_uplift_decrease_dict[treatment_key_i]) / (1-positive_class_proportion)\n",
    "            X_decrease, Y_decrease = make_classification(n_samples=n_all,\n",
    "                                                         n_features=n_uplift_decrease_dict[treatment_key_i],\n",
    "                                                         n_informative=n_uplift_decrease_dict[treatment_key_i],\n",
    "                                                         n_redundant=0,\n",
    "                                                         n_clusters_per_class=1,\n",
    "                                                         weights=[1-adjust_class_proportion, adjust_class_proportion])\n",
    "            for xi in range(n_uplift_decrease_dict[treatment_key_i]):\n",
    "                x_name_i = 'x' + str(len(x_name)+1) + '_uplift_decrease'\n",
    "                x_name.append(x_name_i)\n",
    "                x_uplift_decrease_name.append(x_name_i)\n",
    "                df_res[x_name_i] = X_decrease[:, xi]\n",
    "            Y[treatment_index] = Y[treatment_index] - Y_decrease[treatment_index]\n",
    "            if n_uplift_decrease_mix_informative_dict[treatment_key_i] > 0:\n",
    "                for xi in range(n_uplift_decrease_mix_informative_dict[treatment_key_i]):\n",
    "                    x_name_i = 'x' + str(len(x_name)+1) + '_decrease_mix'\n",
    "                    x_name.append(x_name_i)\n",
    "                    df_res[x_name_i] = (np.random.uniform(-1, 1) * df_res[np.random.choice(x_informative_name)]\n",
    "                                        + np.random.uniform(-1, 1) * df_res[np.random.choice(x_uplift_decrease_name)])\n",
    "\n",
    "    # truncate Y\n",
    "    Y = np.clip(Y, 0, 1)\n",
    "\n",
    "    df_res[y_name] = Y\n",
    "    df_res['treatment_effect'] = Y - Y1\n",
    "    return df_res, x_name"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
