{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/diegoolaya/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.ensemble.forest module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/Users/diegoolaya/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.ensemble.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64000, 12)\n"
     ]
    }
   ],
   "source": [
    "from ipynb.fs.full._init_ import *\n",
    "os.getcwd()\n",
    "df = pd.read_csv(\"http://www.minethatdata.com/Kevin_Hillstrom_MineThatData_E-MailAnalytics_DataMiningChallenge_2008.03.20.csv\")\n",
    "df[\"segment\"] = df[\"segment\"].astype(\"category\")\n",
    "df[\"history_segment\"] = df[\"history_segment\"].astype(\"category\")\n",
    "df[\"zip_code\"] = df[\"zip_code\"].astype(\"category\")\n",
    "df[\"channel\"] = df[\"channel\"].astype(\"category\")\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 'segment'\n",
    "Y = 'visit'\n",
    "nonpredictors = [T,Y]\n",
    "X = [variable for variable in list(df.columns) if variable not in nonpredictors]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df[T] != \"Mens E-Mail\"]#Mens E-Mail\n",
    "df[T] = np.where(df[T] == 'Womens E-Mail',1,0)\n",
    "df = df.reset_index(drop=True)  \n",
    "predictors_4_dummy = [\"history_segment\",\"zip_code\",\"channel\"]\n",
    "df_predictors_4_dummy = pd.get_dummies(df[predictors_4_dummy], prefix_sep='_', drop_first = True)\n",
    "X_dummies = list(df_predictors_4_dummy.columns)\n",
    "X = [variable for variable in X if variable not in predictors_4_dummy]\n",
    "df_predictors = pd.concat([df_predictors_4_dummy,df[X]],axis =1)\n",
    "X = list(df_predictors.columns)\n",
    "df = pd.concat([df[Y],df[T],df_predictors[X]],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descriptive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "segment      0      1\n",
      "visit                \n",
      "0        19044  18149\n",
      "1         2262   3238\n",
      "Total number of observations = 42693\n",
      "Total number of variables =  17\n",
      "Number of control group observations =  21306\n",
      "Number of treatment group observations =  21387\n",
      "Visit rate treatment =  0.151400383410483\n",
      "Visit rate control =  0.10616727682343002\n",
      "Overall effect =  0.045233106587052985\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Descriptive\n",
    "\"\"\"\n",
    "desc_table = pd.crosstab(index = df[Y], columns = df[T], margins = False)\n",
    "print(desc_table)\n",
    "print(\"Total number of observations =\",df.shape[0])\n",
    "print(\"Total number of variables = \",len(X))\n",
    "print(\"Number of control group observations = \",df[T].value_counts()[0])\n",
    "print(\"Number of treatment group observations = \",df[T].value_counts()[1])\n",
    "print(\"Visit rate treatment = \",desc_table[1][1]/(desc_table[1][1] + desc_table[1][0]))\n",
    "print(\"Visit rate control = \",desc_table[0][1]/(desc_table[0][1] + desc_table[0][0]))\n",
    "print(\"Overall effect = \",desc_table[1][1]/(desc_table[1][1] + desc_table[1][0])-desc_table[0][1]/(desc_table[0][1] + desc_table[0][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Amount_folds = 3\n",
    "folds = create_folds(df,Amount_folds,T,Y,X)   \n",
    "df = folds[1][1]\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "5 folds stratified CV\n",
    "\"\"\"\n",
    "Amount_folds = 5\n",
    "#dump(folds,'folds.sav')\n",
    "# CV\n",
    "folds = create_folds(df,Amount_folds,T,Y,X)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Causal models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "3 causal models: CF,T_learner,S_learner\n",
    "\"\"\"\n",
    "random_state = 100\n",
    "model_names = ['CF','T_learner','S_learner']\n",
    "#xgb.XGBClassifier(objective = \"binary:logistic\",n_estimators = 500, random_state = random_state)#xgb.XGBClassifier(objective = \"binary:logistic\",n_estimators = 100, random_state = random_state)\n",
    "#LogisticRegression(solver='saga',max_iter=3000, random_state = random_state)\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "algorithm_1 = LogisticRegression(solver='saga',max_iter=3000, random_state = random_state)\n",
    "algorithm_2 = LogisticRegression(solver='saga',max_iter=3000, random_state = random_state)\n",
    "algorithm_3 = LogisticRegression(solver='saga',max_iter=3000, random_state = random_state)\n",
    "algorithm_4 = LogisticRegression(solver='saga',max_iter=3000, random_state = random_state)\n",
    "####################################################\n",
    "\n",
    "effect_estimates = []\n",
    "for model in model_names:\n",
    "    effect_estimates.append(fit_causal(folds,T,Y,X,model,algorithm_1,algorithm_2,algorithm_3,algorithm_4))\n",
    "\"\"\"\n",
    "Save estimates:\n",
    "\"\"\"\n",
    "#dump(effect_estimates,'effect_estimates_RF.sav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(effect_estimates,'effect_estimates_LR.sav')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qini_in:  [0.027363485657977894]\n",
      "Qini_sen:  [0.018772365706897796]\n",
      "Prof_in:  [-3.650144211773628]\n",
      "Prof_se:  [-3.6274656495852153]\n",
      "MP_in_val:  [0.0]\n",
      "MP_sen_val:  [0.0]\n",
      "MP_in_index:  [0]\n",
      "MP_sen_index:  [0]\n"
     ]
    }
   ],
   "source": [
    "import statistics \n",
    "\"\"\"\n",
    "There is two algoritms:\n",
    "> LR: call \"effect_estimates_LR.sav\"\n",
    "> XGB: call \"effect_estimates_XGB.sav\"\n",
    "\"\"\"\n",
    "effect_estimates= load(\"effect_estimates_XGB.sav\")\n",
    "\"\"\"\n",
    "and three causal models (CF,T_learner,S_learner) where:\n",
    "> CF = effect_estimates[0]\n",
    "> T_learner = effect_estimates[1]\n",
    "> S_learner = effect_estimates[2]\n",
    "\n",
    "\"\"\"\n",
    "model_predictions = effect_estimates[2]\n",
    "\n",
    "\"\"\"\n",
    "The OB and TC matrices\n",
    "\"\"\"\n",
    "def create_OB(b_11,b_10,b_01,b_00):\n",
    "    OB = [[b_00,b_01],[b_10,b_11]]\n",
    "    return OB;\n",
    "\n",
    "def create_TC(c_11,c_10,c_01,c_00):\n",
    "    TC = [[c_00,c_01],[c_10,c_11]]\n",
    "    return TC;\n",
    "\n",
    "\"\"\"\n",
    "Specify the b and c parameters:\n",
    "\"\"\"\n",
    "#b = [10,100,200]\n",
    "b = [100]\n",
    "#benefit = 10\n",
    "#c_pro = [0.2,0.3,0.4]\n",
    "c = 0.1\n",
    "\n",
    "av_qini_insensitive = []\n",
    "av_qini_sensitive = []\n",
    "std_qini_insensitive = []\n",
    "std_qini_sensitive = []\n",
    "av_profit_insensitive = []\n",
    "av_profit_sensitive = []\n",
    "std_profit_insensitive = []\n",
    "std_profit_sensitive = []\n",
    "max_profit_sensitive = []\n",
    "max_profit_insensitive = []\n",
    "MP_sen_index = []\n",
    "MP_sen_val = []\n",
    "MP_in_index = []\n",
    "MP_in_val = []\n",
    "\n",
    "for benefit in b:\n",
    "    \n",
    "    \"\"\"\n",
    "    Equal benefits\n",
    "    \"\"\"\n",
    "    benefit_pos = benefit\n",
    "    benefit_neg = benefit*1.2\n",
    "    cost_pos = benefit_pos*c\n",
    "    cost_neg = benefit_pos*c\n",
    "    \n",
    "    \"\"\"\n",
    "    OB and TC matrices\n",
    "    \"\"\"\n",
    "    OB = create_OB(benefit_pos,benefit_neg,0,0)\n",
    "    TC = create_TC(cost_pos,0,cost_neg,0)\n",
    "    \n",
    "    \"\"\"\n",
    "    Gamma and delta:\n",
    "    \"\"\"\n",
    "    gamma = (OB[0][0] - TC[0][0] - OB[0][1] + TC[0][1])/(OB[1][0] - TC[1][0] - OB[0][0] + TC[0][0])\n",
    "    delta = (OB[1][0] - TC[1][0] + OB[0][1] - TC[0][1] - OB[1][1] + TC[1][1] - OB[0][0] + TC[0][0])/(OB[1][0] - TC[1][0] - OB[0][0] + TC[0][0])\n",
    "\n",
    "    qini_sensitive = []\n",
    "    qini_insensitive = []\n",
    "    profit_sensitive = []\n",
    "    profit_insensitive = []\n",
    "    list_sen_prof = []\n",
    "    list_ins_prof = []\n",
    "    for fold in list(range(len(model_predictions))):\n",
    "        \"\"\"\n",
    "        Qini\n",
    "        \"\"\"\n",
    "        perf_table_sensitive = performance_profit(model_predictions,gamma,delta,True,\"qini\",\"Profit-sensitive\")\n",
    "        perf_table_insensitive = performance_profit(model_predictions,gamma,delta,False,\"qini\",\"Profit-insensitive\")\n",
    "        qini_sensitive.append(qini_metric(perf_table_sensitive[fold]))\n",
    "        qini_insensitive.append(qini_metric(perf_table_insensitive[fold]))\n",
    "        \"\"\"\n",
    "        Profit\n",
    "        \"\"\"\n",
    "        prof_table_sensitive = performance_profit(model_predictions,gamma,delta,True,\"Profit\",\"Profit-sensitive\")\n",
    "        prof_table_insensitive = performance_profit(model_predictions,gamma,delta,False,\"Profit\",\"Profit-insensitive\")\n",
    "        \"\"\"\n",
    "        Average profit:\n",
    "        \"\"\"\n",
    "        profit_sensitive.append(prof_table_sensitive[fold].iloc[:,1].mean())\n",
    "        profit_insensitive.append(prof_table_insensitive[fold].iloc[:,1].mean())\n",
    "        \"\"\"\n",
    "        Max. profit and fractions\n",
    "        \"\"\"\n",
    "        list_sen_prof.append(prof_table_sensitive[fold].iloc[:,1])\n",
    "        list_ins_prof.append(prof_table_insensitive[fold].iloc[:,1])\n",
    "        \n",
    "    max_profit_sensitive = pd.concat(list_sen_prof, axis = 1)\n",
    "    max_profit_sensitive['mean'] = max_profit_sensitive.mean(axis=1)\n",
    "    MP_sen_index.append(max_profit_sensitive['mean'].idxmax())\n",
    "    MP_sen_val.append(max(max_profit_sensitive['mean']))\n",
    "\n",
    "    max_profit_insensitive = pd.concat(list_ins_prof, axis = 1)\n",
    "    max_profit_insensitive['mean'] = max_profit_insensitive.mean(axis=1)\n",
    "    MP_in_index.append(max_profit_insensitive['mean'].idxmax())\n",
    "    MP_in_val.append(max(max_profit_insensitive['mean']))\n",
    "\n",
    "    # Qini results\n",
    "    av_qini_insensitive.append(statistics.mean(qini_insensitive))\n",
    "    av_qini_sensitive.append(statistics.mean(qini_sensitive))\n",
    "    std_qini_insensitive.append(statistics.stdev(qini_insensitive))\n",
    "    std_qini_sensitive.append(statistics.stdev(qini_sensitive))\n",
    "    \n",
    "    # Profit results\n",
    "    av_profit_insensitive.append(statistics.mean(profit_insensitive))\n",
    "    av_profit_sensitive.append(statistics.mean(profit_sensitive))\n",
    "    std_profit_insensitive.append(statistics.stdev(profit_insensitive))\n",
    "    std_profit_sensitive.append(statistics.stdev(profit_sensitive))\n",
    "    \n",
    "print(\"Qini_in: \",av_qini_insensitive) \n",
    "print(\"Qini_sen: \",av_qini_sensitive)\n",
    "#print(std_qini_insensitive)\n",
    "#print(std_qini_sensitive)\n",
    "print(\"Prof_in: \",av_profit_insensitive) \n",
    "print(\"Prof_se: \",av_profit_sensitive)\n",
    "#print(std_profit_insensitive)\n",
    "#print(std_profit_sensitive)\n",
    "print(\"MP_in_val: \",MP_in_val)\n",
    "print(\"MP_sen_val: \",MP_sen_val)\n",
    "print(\"MP_in_index: \",MP_in_index)\n",
    "print(\"MP_sen_index: \",MP_sen_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots\n",
    "#### Qini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Plot the Qini curves\n",
    "\"\"\"\n",
    "performance_to_plot_sensitive = performance_profit(model_predictions,gamma,delta,True,\"qini\",\"Profit-sensitive\")\n",
    "performance_to_plot_insensitive = performance_profit(model_predictions,gamma,delta,False,\"qini\",\"Profit-insensitive\")\n",
    "performance_to_plot_sensitive = pd.melt(pd.concat(performance_to_plot_sensitive), ['x'])\n",
    "performance_to_plot_insensitive = pd.melt(pd.concat(performance_to_plot_insensitive),['x'])\n",
    "performance_to_plot = pd.concat([performance_to_plot_sensitive,performance_to_plot_insensitive])\n",
    "performance_to_plot.columns = ['x','Approach',\"Value\"]\n",
    "sns.set_style(\"white\")\n",
    "ax = sns.lineplot(x='x', y= 'Value', hue='Approach', style = 'Approach',lw=1,data = performance_to_plot)\n",
    "plt.xlabel(\"Targeted proportion\")\n",
    "plt.ylabel(\"Cumulative Qini\")\n",
    "#plt.xticks(np.linspace(0, 100, 11, endpoint = True))\n",
    "#ax.legend(loc = 4, frameon = False, ncol = 1, labelspacing= 0.2)\n",
    "#plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.legend(loc=4, borderaxespad=0.1)\n",
    "#fig_uplift = ax.get_figure()\n",
    "#fig_uplift.savefig('Qini_Hillstrom.pdf',bbox_inches='tight',transparent =True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Profit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics \n",
    "\"\"\"\n",
    "Plot the profit curve\n",
    "    > Specify algoritm: \"effect_estimates_XGB.sav\"\n",
    "    > Specify causal model: effect_estimates[0]\n",
    "\"\"\"\n",
    "\n",
    "effect_estimates= load(\"effect_estimates_XGB.sav\")\n",
    "model_predictions = effect_estimates[1]\n",
    "\n",
    "def create_OB(b_11,b_10,b_01,b_00):\n",
    "    OB = [[b_00,b_01],[b_10,b_11]]\n",
    "    return OB;\n",
    "\n",
    "def create_TC(c_11,c_10,c_01,c_00):\n",
    "    TC = [[c_00,c_01],[c_10,c_11]]\n",
    "    return TC;\n",
    "\n",
    "\"\"\"\n",
    "Specify benefit and cost parameters\n",
    "\"\"\"\n",
    "benefit = 100\n",
    "c = 0.2\n",
    "benefit_pos = benefit\n",
    "benefit_neg = benefit\n",
    "    \n",
    "OB = create_OB(benefit_pos,benefit_neg,0,0)\n",
    "TC = create_TC(benefit_pos*c,0,(benefit_pos*c)*c,0)\n",
    "#TC = create_TC(benefit_pos*c,0,benefit_pos*c,0)\n",
    "    \n",
    "gamma = (OB[0][0] - TC[0][0] - OB[0][1] + TC[0][1])/(OB[1][0] - TC[1][0] - OB[0][0] + TC[0][0])\n",
    "delta = (OB[1][0] - TC[1][0] + OB[0][1] - TC[0][1] - OB[1][1] + TC[1][1] - OB[0][0] + TC[0][0])/(OB[1][0] - TC[1][0] - OB[0][0] + TC[0][0])\n",
    "\n",
    "performance_to_plot_sensitive = performance_profit(model_predictions,gamma,delta,True,\"profit\",\"Profit-sensitive\")\n",
    "performance_to_plot_insensitive = performance_profit(model_predictions,gamma,delta,False,\"profit\",\"Profit-insensitive\")\n",
    "performance_to_plot_sensitive = pd.melt(pd.concat(performance_to_plot_sensitive), ['x'])\n",
    "performance_to_plot_insensitive = pd.melt(pd.concat(performance_to_plot_insensitive),['x'])\n",
    "performance_to_plot = pd.concat([performance_to_plot_sensitive,performance_to_plot_insensitive])\n",
    "performance_to_plot.columns = ['x','Approach',\"Value\"]\n",
    "sns.set_style(\"white\")\n",
    "flatui = [\"#1f77b4\", \"#2ca02c\"]\n",
    "ax = sns.lineplot(x='x', y= 'Value', hue='Approach', palette=flatui,lw=1,data = performance_to_plot)\n",
    "plt.xlabel(\"Targeted proportion\")\n",
    "plt.ylabel(\"Profit per instance\")\n",
    "#plt.xticks(np.linspace(0, 100, 11, endpoint = True))\n",
    "#ax.legend(loc = 4, frameon = False, ncol = 1, labelspacing= 0.2)\n",
    "#plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "#plt.legend(loc=2, borderaxespad=0.1)#loc = 4\n",
    "#fig_uplift = ax.get_figure()\n",
    "#fig_uplift.savefig('b10_CF_Criteo.pdf',bbox_inches='tight',transparent =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Estimates the Qini and the profit\n",
    "\"\"\"\n",
    "def performance_profit(model_predictions,gamma,delta,frontier,metric,approach_name):\n",
    "    \n",
    "    \"\"\"\n",
    "    Lenght of the bins: here is 100 but can be any number\n",
    "    \"\"\"\n",
    "    len_fold = []\n",
    "    for fold in list(range(len(model_predictions))):\n",
    "        len_fold.append(len(model_predictions[fold]))\n",
    "    min_lenght_folds = min(len_fold)\n",
    "    min_lenght_folds = 100\n",
    "    \n",
    "    \"\"\"\n",
    "    Obtain the performance table:\n",
    "    \"\"\"\n",
    "    def performance_table(df,min_lenght_folds,frontier,metric,approach_name):\n",
    "        if frontier == True:\n",
    "            df['tau'] = gamma + delta*df['Prob_treat']\n",
    "            df['target'] = np.where(df['s'] >= df['tau'],1,-1)\n",
    "            #df['d'] = abs(delta*df.loc[:,'Prob_treat'] - df.loc[:,'s']+gamma)/(math.sqrt((delta**2)+1))#*df['target']\n",
    "            df['d'] = (df.loc[:,'s'] - delta*df.loc[:,'Prob_treat'] - gamma)/(math.sqrt((delta**2)+1))\n",
    "            df_sorted = df.sort_values(by = [\"d\"], ascending = False).reset_index(drop=True)\n",
    "        else:\n",
    "            df_sorted = df.sort_values(by = [\"s\"], ascending = False).reset_index(drop=True)\n",
    "        \n",
    "        df_sorted[\"ranking\"] =  list(range(1,len(df_sorted)+1))\n",
    "        labels = list(range(1,min_lenght_folds+1))\n",
    "        df_sorted[\"bin\"] = pd.cut(df_sorted['ranking'], len(labels), labels = labels).astype(int)\n",
    "        df_sorted.index = df_sorted.index + 1\n",
    "        df_sorted[\"ct\"] = np.where(df_sorted[T]==0,1,0)\n",
    "        df_sorted[\"y_tr\"] = np.where((df_sorted[T]==1) & (df_sorted[Y]==1) ,1,0)\n",
    "        df_sorted[\"y_ct\"] = np.where((df_sorted[T]==0) & (df_sorted[Y]==1) ,1,0)\n",
    "        n_t = df_sorted.pivot_table(index='bin', values= T, aggfunc='sum')\n",
    "        n_c = df_sorted.pivot_table(index='bin', values= \"ct\", aggfunc='sum')\n",
    "        n_y1_t = df_sorted.pivot_table(index='bin', values= 'y_tr', aggfunc='sum')\n",
    "        n_y1_c = df_sorted.pivot_table(index='bin', values= \"y_ct\", aggfunc='sum')\n",
    "        s_t = pd.concat([n_c,n_t,n_y1_c,n_y1_t], axis = 1)\n",
    "        s_t.columns = [\"n_c\",\"n_t\",\"n_y1_c\",\"n_y1_t\"]\n",
    "        s_t[\"n_y0_t\"] = s_t[\"n_t\"] - s_t[\"n_y1_t\"]\n",
    "        s_t[\"n_y0_c\"] = s_t[\"n_c\"] - s_t[\"n_y1_c\"]\n",
    "        s_t[\"bin\"] = s_t.index\n",
    "        s_t[\"cumsum_n_t\"] = s_t[\"n_t\"].cumsum()\n",
    "        s_t[\"cumsum_n_c\"] = s_t[\"n_c\"].cumsum()\n",
    "        s_t[\"cumsum_n_y1_t\"] = s_t[\"n_y1_t\"].cumsum()\n",
    "        s_t[\"cumsum_n_y1_c\"] = s_t[\"n_y1_c\"].cumsum()\n",
    "        s_t[\"cumsum_n_y0_t\"] = s_t[\"n_y0_t\"].cumsum()\n",
    "        s_t[\"cumsum_n_y0_c\"] = s_t[\"n_y0_c\"].cumsum()\n",
    "        \n",
    "        s_t[\"e11\"] = s_t[\"cumsum_n_y1_t\"]/s_t[\"cumsum_n_t\"].iloc[-1]\n",
    "        s_t[\"e10\"] = s_t[\"cumsum_n_y1_c\"]/s_t[\"cumsum_n_c\"].iloc[-1]\n",
    "        s_t[\"e01\"] = s_t[\"cumsum_n_y0_t\"]/s_t[\"cumsum_n_t\"].iloc[-1]\n",
    "        s_t[\"e00\"] = s_t[\"cumsum_n_y0_c\"]/s_t[\"cumsum_n_c\"].iloc[-1]\n",
    "        s_t[\"e11-e10\"] = s_t[\"e11\"] - s_t[\"e10\"]\n",
    "        \n",
    "        \"\"\"\n",
    "        Calculate the Qini at each threshold\n",
    "        \"\"\"\n",
    "        s_t[\"qini\"] = s_t[\"cumsum_n_y1_t\"] - (s_t[\"cumsum_n_y1_c\"]*s_t[\"cumsum_n_t\"])/s_t[\"cumsum_n_c\"]\n",
    "        s_t = s_t.replace(to_replace = np.nan, value = 0) \n",
    "        overall_inc_gains = s_t[\"qini\"].iloc[-1]\n",
    "        random_inc_gains = np.append([0],np.cumsum(np.repeat(overall_inc_gains / (s_t.loc[s_t.index[-1], \"bin\"]),(s_t.loc[s_t.index[-1], \"bin\"]))))\n",
    "        \n",
    "        \"\"\"\n",
    "        Calculate the profit at each threshold:\n",
    "        \"\"\"\n",
    "        net_ben_T_1 = OB[1][1] - TC[1][1]\n",
    "        net_ben_C_1 = OB[1][0] - TC[1][0]\n",
    "        net_ben_T_0 = OB[0][1] - TC[0][1]\n",
    "        net_ben_C_0 = OB[0][0] - TC[0][0]\n",
    "        s_t['profit'] = s_t[\"e11\"]*net_ben_T_1 - s_t[\"e10\"]*net_ben_C_1 + s_t[\"e01\"]*net_ben_T_0 - s_t[\"e00\"]*net_ben_C_0\n",
    "        #s_t['profit'] = s_t[\"e11-e10\"]*OB[1][1] - s_t[\"e11\"]*TC[1][1] - s_t[\"e01\"]*TC[0][1]\n",
    "        s_t = s_t.replace(to_replace = np.nan, value = 0) \n",
    "\n",
    "        # Qini\n",
    "        qini = s_t[\"qini\"]\n",
    "        qini = pd.Series(qini).values\n",
    "        qini = np.append([0],qini)\n",
    "\n",
    "        # Profit\n",
    "        profit = s_t['profit']\n",
    "        profit = pd.Series(profit).values\n",
    "        profit = np.append([0],profit)\n",
    "\n",
    "        # X axis\n",
    "        x = s_t[\"bin\"]/(s_t.loc[s_t.index[-1], \"bin\"])\n",
    "        x = pd.Series(x).values\n",
    "        x = np.append([0],x)\n",
    "        \n",
    "        if metric == \"qini\":\n",
    "            performance_table = pd.DataFrame(list(zip(x,qini, random_inc_gains)),columns =['x',approach_name, 'Random'])\n",
    "        else:\n",
    "            performance_table = pd.DataFrame(list(zip(x,profit)),columns =['x',approach_name])\n",
    "            \n",
    "        \"\"\"\n",
    "        Testing:\n",
    "        \"\"\"\n",
    "        cum_nt = s_t[\"cumsum_n_y1_c\"]\n",
    "        cum_nt = pd.Series(cum_nt).values\n",
    "        cum_nt = np.append([0],cum_nt)\n",
    "        perf_testing = pd.DataFrame(list(zip(x,cum_nt)),columns =['x',approach_name])\n",
    "        perf_testing[approach_name] = perf_testing[approach_name]/perf_testing[approach_name].iloc[-1]\n",
    "\n",
    "        \n",
    "        p11_ITEs = pd.concat([df[Y],df[T],df['Prob_treat'],df['s']], axis = 1)\n",
    "        \n",
    "        return performance_table;\n",
    "    \n",
    "    performance_tables_fold = []\n",
    "    for fold in list(range(len(model_predictions))):\n",
    "        performance_tables_fold.append(performance_table(model_predictions[fold],min_lenght_folds,frontier,metric,approach_name))\n",
    "    return performance_tables_fold;\n",
    "\n",
    "\"\"\"\n",
    "Calculate the qini metric (scalar value)\n",
    "\"\"\"\n",
    "\n",
    "def qini_metric(perf_object):\n",
    "    x = list(perf_object.iloc[:,0]/100)\n",
    "    y_inc = list(perf_object.iloc[:,1])\n",
    "    y_ran = list(perf_object.iloc[:,2])\n",
    "    \n",
    "    def auc(x,y):\n",
    "        auc = 0\n",
    "        for i in list(range(1,len(x))):\n",
    "            auc = auc + 0.5 * (x[i] - x[i-1]) * (y[i] + y[i-1])\n",
    "        return auc\n",
    " \n",
    "    auc_inc = auc(x,y_inc)\n",
    "    auc_ran = auc(x,y_ran)\n",
    "    \n",
    "    qini = auc_inc - auc_ran\n",
    "    \n",
    "    return qini;\n",
    "\n",
    "#performance_profit(model_predictions,gamma,delta,True,\"Profit\",\"Profit-sensitive\")[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Plots of cumulative positive instances in T and C\n",
    "\"\"\"\n",
    "performance_to_plot_sensitive = performance_profit(model_predictions,gamma,delta,True,\"qini\",\"sensitive\")\n",
    "performance_to_plot_insensitive = performance_profit(model_predictions,gamma,delta,False,\"qini\",\"insensitive\")\n",
    "performance_to_plot_sensitive = pd.melt(pd.concat(performance_to_plot_sensitive), ['x'])\n",
    "performance_to_plot_insensitive = pd.melt(pd.concat(performance_to_plot_insensitive),['x'])\n",
    "performance_to_plot = pd.concat([performance_to_plot_sensitive,performance_to_plot_insensitive])\n",
    "performance_to_plot.columns = ['x','Approach',\"Value\"]\n",
    "sns.set_style(\"white\")\n",
    "ax = sns.lineplot(x='x', y= 'Value', hue='Approach', style = 'Approach',lw=1,data = performance_to_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "effect_estimates= load(\"effect_estimates_LR.sav\")\n",
    "model_predictions = effect_estimates[1]\n",
    "\"\"\"\n",
    "Distribution P11\n",
    "\"\"\"\n",
    "import seaborn as sns\n",
    "\n",
    "perf_dist = performance_profit(model_predictions,gamma,delta,True,\"profit\",\"Profit-sensitive\")\n",
    "perf_dist = pd.concat(perf_dist, axis = 0)\n",
    "perf_dist_t = perf_dist.loc[(perf_dist[T] == 1) & (perf_dist[Y] == 1)]\n",
    "perf_dist_c = perf_dist.loc[(perf_dist[T] == 0) & (perf_dist[Y] == 1)]\n",
    "\n",
    "sns.kdeplot( perf_dist_t[\"Prob_treat\"] ,shade=True, color=\"skyblue\")\n",
    "sns.kdeplot( perf_dist_c[\"Prob_treat\"] ,shade=True, color=\"teal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Distribution ITE\n",
    "\"\"\"\n",
    "sns.kdeplot( perf_dist_t[\"s\"] ,shade=True, color=\"skyblue\")\n",
    "sns.kdeplot( perf_dist_c[\"s\"] ,shade=True, color=\"teal\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
